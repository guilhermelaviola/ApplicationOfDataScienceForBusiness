{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQeT21vJhx1UGFtIXgdwk+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guilhermelaviola/ApplicationOfDataScienceForBusiness/blob/main/Class12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Personalized Recommendation with Data Science**\n",
        "Personalized recommendations are a fundamental strategy for companies that want to increase engagement, sales, and customer loyalty, using data analysis and algorithms to identify patterns of behavior and individual preferences. Widely applied in sectors such as e-commerce, streaming, and financial services, it can be implemented through different techniques, such as Collaborative Filtering (based on users or items), Content-Based Filtering (which considers item characteristics and user profile), and Hybrid Methods, which combine both to maximize results. The choice of approach depends on the business needs and data availability. Implementation involves steps such as data collection and preprocessing, model building, training, and evaluation—potentially using tools like the Surprise library in Python—as well as the selection of algorithms such as SVD. Performance evaluation is done using metrics such as RMSE and MAE. When well applied, personalized recommendations significantly contribute to generating value and creating more relevant and engaging experiences for users."
      ],
      "metadata": {
        "id": "KyFgSuUWZkao"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Okh_pGGDY4e_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81ee0061-604e-49f3-b93c-0177a3c616e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting surprise\n",
            "  Using cached surprise-0.1-py2.py3-none-any.whl.metadata (327 bytes)\n",
            "Collecting scikit-surprise (from surprise)\n",
            "  Using cached scikit_surprise-1.1.4.tar.gz (154 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-surprise->surprise) (1.5.3)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-surprise->surprise) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-surprise->surprise) (1.16.3)\n",
            "Downloading surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp312-cp312-linux_x86_64.whl size=2554981 sha256=f462bcaaa3f7683586a4db489f2f612944985c17645a623214559d2dc83c565f\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/fa/bc/739bc2cb1fbaab6061854e6cfbb81a0ae52c92a502a7fa454b\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise, surprise\n",
            "Successfully installed scikit-surprise-1.1.4 surprise-0.1\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "!pip install surprise\n",
        "from surprise import Dataset, Reader, SVD, accuracy\n",
        "from surprise.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Example: Surprise Library**\n",
        "The most important thing to understand is that the Surprise library allows us to implement recommendation systems efficiently. However, the quality of the input data is crucial to obtaining accurate and useful results. Using historical and properly processed data, it's possible to build a recommendation model that meets specific consumer needs."
      ],
      "metadata": {
        "id": "mLT92-cpn0bO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating fictional data:\n",
        "data = {\n",
        "    'user_id': [1, 1, 1, 2, 2, 3, 3, 4],\n",
        "    'item_id': [1, 2, 3, 1, 2, 2, 3, 1],\n",
        "    'rating': [5, 3, 2, 5, 4, 3, 5, 4]\n",
        "}\n",
        "\n",
        "# Transforming the data above into a DataFrame:\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Using the Reader to define the data format:\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "data = Dataset.load_from_df(df[['user_id', 'item_id', 'rating']], reader)"
      ],
      "metadata": {
        "id": "ijeqdaglZtnl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividing the data into training and test:\n",
        "train_set, test_set = train_test_split(data, test_size=0.25)\n",
        "\n",
        "# Using the SVD algorithm:\n",
        "algo = SVD()\n",
        "algo.fit(train_set)\n",
        "\n",
        "# Making predictions:\n",
        "predictions = algo.test(test_set)\n",
        "\n",
        "# Evaluating the model accuracy:\n",
        "accuracy.rmse(predictions)\n",
        "accuracy.mae(predictions)"
      ],
      "metadata": {
        "id": "Vr-1BXxZaIPj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ae8b5ad-746f-42eb-f176-4fb7c37ea246"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 1.1115\n",
            "MAE:  1.1101\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.110068230584842"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying the top 5 recommendations for a specific user\n",
        "user_id = 1\n",
        "user_items = df[df['user_id'] == user_id]['item_id']\n",
        "all_items = set(df['item_id'].unique())\n",
        "items_to_predict = list(all_items - set(user_items))\n",
        "\n",
        "recommendations = []\n",
        "for item_id in items_to_predict:\n",
        "  score = algo.predict(user_id, item_id).est\n",
        "  recommendations.append((item_id, score))\n",
        "\n",
        "recommendations.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Top 5 recommendations:\n",
        "top_5 = recommendations[:5]\n",
        "print(f\"Top 5 recommendations for user {user_id}:\")\n",
        "\n",
        "for item, score in top_5:\n",
        "  print(f\"Item {item} with score {score:.2f}\")"
      ],
      "metadata": {
        "id": "kjkC3J71a0hw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33271f57-308a-40f5-becd-45899c07e0de"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 recommendations for user 1:\n"
          ]
        }
      ]
    }
  ]
}